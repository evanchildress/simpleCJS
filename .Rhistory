inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1))}
params<-c("a","b")
inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1))}
params<-c("a","b")
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=nchains,
n.iter=niter,
n.burnin=nburn
)
inits()
nchains
cat("model{
a~dnorm(0,1)
b~dnorm(0,1)
for(i in 1:100){
y[i]~a+b*x[i]
}
}",file="test.txt")
inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1))}
params<-c("a","b")
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=nchains,
n.iter=niter,
n.burnin=nburn
)
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=1,
n.iter=niter,
n.burnin=nburn
)
length(inits)
length(inits)==nchains
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=2,
n.iter=niter,
n.burnin=nburn
)
cat("model{
a~dnorm(0,0.1)
b~dnorm(0,0.1)
eps~dunif(0,4)
for(i in 1:100){
y[i]~dnorm(a+b*x[i],eps)
}
}",file="test.txt")
inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1),eps=runif(1,0,4))}
params<-c("a","b","eps")
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=2,
n.iter=niter,
n.burnin=nburn
)
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=3,
n.iter=niter,
n.burnin=nburn
)
inits()
bla
bla<-list(x=x,y=x*2+10+rnorm(0,0.1))
bla
x
x*2+10+rnorm(0,0.1)
bla<-list(x=x,y=x*2+10+rnorm(100,0,0.1))
bla
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=3,
n.iter=niter,
n.burnin=nburn
)
names(inits())
doo<-inits()
out<-jags(data=bla,
inits=doo,
parameters.to.save=params,
model.file='test.txt',
n.chains=3,
n.iter=niter,
n.burnin=nburn
)
doo
nb <- 500
ni <- 1000
nt <- 5
nc <- 1
x<-rnorm(100,10,1)
bla<-list(x=x,y=x*2+10+rnorm(100,0,0.1))
cat("model{
a~dnorm(0,0.1)
b~dnorm(0,0.1)
eps~dunif(0,4)
for(i in 1:100){
y[i]~dnorm(a+b*x[i],eps)
}
}",file="test.txt")
inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1),eps=runif(1,0,4))}
params<-c("a","b","eps")
out<-jags(data=bla,
inits=doo,
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
inits()
nb <- 500
ni <- 1000
nt <- 5
nc <- 1
x<-rnorm(100,10,1)
bla<-list(x=x,y=x*2+10+rnorm(100,0,0.1))
cat("model{
a~dnorm(0,0.1)
b~dnorm(0,0.1)
eps~dunif(0,4)
for(i in 1:100){
y[i]~dnorm(a+b*x[i],eps)
}
}",file="test.txt")
inits<-function(){list(a=rnorm(1,0,1),b=rnorm(1,0,1),eps=runif(1,0,4))}
params<-c("a","b","eps")
out<-jags(data=bla,
inits=doo,
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
inits()
bla
inits()
source('~/.active-rstudio-document', echo=TRUE)
out<-jags(data=bla,
inits=list(inits()),
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
out
source('~/.active-rstudio-document', echo=TRUE)
out
nc
source('~/.active-rstudio-document', echo=TRUE)
require(R2jags)
out<-jags(data=bla,
inits=list(inits()),
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
out<-jags(data=bla,
inits=inits(),
parameters.to.save=params,
model.file='test.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt
)
simNum <- 1
rDataName <- 'dMDataOutbkt2002_2014.RData'
dataStore<-"~/process-data/data_store/processed_data"
##########
comment<-paste(" model",simNum, " MS Sim "  )
home <- file.path("~/simpleCJS")
setwd( home )
directory <- tempfile( pattern="output-", tmpdir ='.', fileext='-simpleCJS')
dir.create(directory)
bugsName <- paste0('./simpleCJS','.bugs')
file.copy(from='./callSimpleCJS.R', to=paste(directory,'callSimpleCJS.R',sep='/'))
file.copy(from=bugsName , to=paste(directory,bugsName ,sep='/'))
#file.copy(from='./analyzeSimpleCJS.R', to=paste(directory,'analyzeSimpleCJS.R',sep='/'))
file.copy(from='./run.R', to=paste(directory,'run.R',sep='/'))
##################
#file.copy(from=paste(rDataName,sep=''), to=paste(directory,rDataName,sep='/'))
##################
fileOutName <- "outMSRiver.RData"
#load(paste(home,'/',rDataName,simNum,'.RData',sep=''))
####################
load(file.path(dataStore,rDataName))
library(plyr)
library(rjags)
library(ggplot2)
library(abind)
rjags::load.module("dic")
dMData$length[dMData$tagNumberCH=='1BF1FF6207' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='1BF1FF6521' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='1BF18CE7ED' & dMData$season == 2 & dMData$year == 2006] <- NA
dMData$length[dMData$tagNumberCH=='1BF20FF1B9' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='257C67CA48' ] <- NA
dMData$length[dMData$tagNumberCH=='1BF20EB7A4' & dMData$season == 4 & dMData$year == 2008] <- NA
nrow(dMData)
dMData<-dMData[1:10000]
library(plyr)
library(rjags)
library(ggplot2)
library(abind)
rjags::load.module("dic")
dMData$length[dMData$tagNumberCH=='1BF1FF6207' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='1BF1FF6521' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='1BF18CE7ED' & dMData$season == 2 & dMData$year == 2006] <- NA
dMData$length[dMData$tagNumberCH=='1BF20FF1B9' & dMData$season == 3 & dMData$year == 2005] <- NA
dMData$length[dMData$tagNumberCH=='257C67CA48' ] <- NA
dMData$length[dMData$tagNumberCH=='1BF20EB7A4' & dMData$season == 4 & dMData$year == 2008] <- NA
#dMData$riverOrdered <- factor(dMData$river,levels=c('WEST BROOK','WB JIMMY','WB MITCHELL','WB OBEAR'), ordered=T)
# means for standardizing
#####################################################################
# stdBySeasonRiver <- ddply( dMData, .(riverOrdered,riverN,season), summarise,
#  lengthMean=mean(length, na.rm=TRUE),
#  lengthSd=sd(length, na.rm=TRUE),
#  lengthLo = quantile(length,c(0.025), na.rm=TRUE),
#  lengthHi = quantile(length,c(0.975), na.rm=TRUE),
#  tempMean=mean(fullMeanT, na.rm=TRUE),
#  tempMeanP=mean(temperatureForP, na.rm=TRUE),
#  tempSd=sd(fullMeanT, na.rm=TRUE),
#  tempSdP=sd(temperatureForP, na.rm=TRUE),
#  tempLo = quantile(fullMeanT,c(0.025), na.rm=TRUE),
#  tempHi = quantile(fullMeanT,c(0.975), na.rm=TRUE),
#  flowMean=mean(fullMeanD, na.rm=TRUE),
#  flowSd=sd(fullMeanD, na.rm=TRUE),
#  dischMeanP=mean(dischargeForP,na.rm=T),
#  dischSdP=sd(dischargeForP,na.rm=T),
#  flowLo = quantile(fullMeanD,c(0.025), na.rm=TRUE),
#  flowHi = quantile(fullMeanD,c(0.975), na.rm=TRUE) )
# ############# To get rid of NA Rivers
# stdBySeasonRiver<-stdBySeasonRiver[!is.na(stdBySeasonRiver$riverN),]
#
# #####################################################################
# stdBySeason <- ddply( dMData, .(season), summarise,
#  lengthMean=mean(length, na.rm=TRUE),
#  lengthSd=sd(length, na.rm=TRUE),
#  lengthLo = quantile(length,c(0.025), na.rm=TRUE),
#  lengthHi = quantile(length,c(0.975), na.rm=TRUE),
#  tempMean=mean(fullMeanT, na.rm=TRUE),
#  tempMeanP=mean(temperatureForP, na.rm=TRUE),
#  tempSd=sd(fullMeanT, na.rm=TRUE),
#  tempSdP=sd(temperatureForP, na.rm=TRUE),
#  tempLo = quantile(fullMeanT,c(0.025), na.rm=TRUE),
#  tempHi = quantile(fullMeanT,c(0.975), na.rm=TRUE),
#  flowMean=mean(fullMeanD, na.rm=TRUE),
#  flowSd=sd(fullMeanD, na.rm=TRUE),
#  dischMeanP=mean(dischargeForP,na.rm=T),
#  dischSdP=sd(dischargeForP,na.rm=T),
#  flowLo = quantile(fullMeanD,c(0.025), na.rm=TRUE),
#  flowHi = quantile(fullMeanD,c(0.975), na.rm=TRUE) )
#
# # standardize by river  - for age0 fall lengths
# stdByRiver <- ddply( dMData, .(riverOrdered,riverN), summarise,
# lengthSd0 = sd(subset( length, age == 0 & season == 3 ), na.rm=TRUE),
# lengthMean0 = mean(subset( length, age == 0 & season == 3 ), na.rm=TRUE) )
#
# stdByRiver <- stdByRiver[!is.na(stdByRiver$riverN),]
# stdByRiver$river <- as.numeric(stdByRiver$riverOrdered)
#stdBySeasonRiver<-rbind(stdBySeasonRiver,c('zRiv1','0',rep(NA,ncol(stdBySeasonRiver)-2)))
#####
# # fdDATA is flood and drought frequencies and durations
# fdDATA$year <- as.numeric( fdDATA$year )
# fdDATA$year2 <- fdDATA$year
# fdDATA$year <- fdDATA$year-min(fdDATA$year) + 1
#
# floodDur <- matrix(0,max(fdDATA$season),max(fdDATA$year))
# droughtDur <- matrix(0,max(fdDATA$season),max(fdDATA$year))
# floodFreq <- matrix(0,max(fdDATA$season),max(fdDATA$year))
# for ( i in 1:nrow(fdDATA) ){
#   floodDur[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$floodDur[i]
#   droughtDur[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$droughtDur[i]
#   floodFreq[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$floodFreq[i]
#
# }
#####
# function to add dummy rows and columns for zRiv=1
addRowColMeans <- function(m){
m <- cbind( rowMeans(m),m )
m <- rbind( colMeans(m),m )
return ( m )
}
# function to add dummy columns for zRiv=1
addColMeans <- function(m){
m <- cbind( rowMeans(m),m )
return ( m )
}
# tempForN<- array(NA,dim=c(4,5,max(dMData$year-min(dMData$year) + 1)))
# for(s in 1:4){
#   for(y in 1:max(dMData$year-min(dMData$year) + 1)){
#       tempForN[s,1,y]<-(stdBySeason$tempMean[s]- stdBySeason$tempMean[s] ) / stdBySeason$tempSd[ s ]
#     for(r in 1:4){
#       tempForN[s,r+1,y]<-(mean(dMData$fullMeanT[dMData$season==s&as.numeric(dMData$riverOrdered)==r&(dMData$year-min(dMData$year) + 1)==y],na.rm=T)
#                           - stdBySeason$tempMean[ s] ) / stdBySeason$tempSd[ s ]
#       if(tempForN[s,r+1,y]=='NaN')tempForN[s,r+1,y]<-(stdBySeason$tempMean[s]- stdBySeason$tempMean[ s] ) / stdBySeason$tempSd[ s ]
#     }
#   }
# }
# flowForN<- array(NA,dim=c(4,5,max(dMData$year-min(dMData$year) + 1)))
# for(s in 1:4){
#   for(y in 1:max(dMData$year-min(dMData$year) + 1)){
#       flowForN[s,1,y]<-(stdBySeason$flowMean[s]- stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]
#     for(r in 1:4){
#       flowForN[s,r+1,y]<-(mean(dMData$fullMeanD[dMData$season==s&as.numeric(dMData$riverOrdered)==r&(dMData$year-min(dMData$year) + 1)==y],na.rm=T)
#                           - stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]
#       if(flowForN[s,r+1,y]=='NaN')flowForN[s,r+1,y]<-(stdBySeason$flowMean[s]- stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]
#     }
#   }
# }
############ Predictors that are in a matrix have season in rows and river in columns
d <- within(
data = list(),
expr = {
encDATA = as.numeric(dMData$enc) #$msEnc
riverDATA = dMData$riverN #-3
nRivers = length(unique(dMData$riverN))-1 #may need to add one for unobs
lengthDATA = dMData$length
availableDATA = dMData$available01
ind = as.numeric(factor(dMData$tag))
# For standardizing length
#   lengthMean = addColMeans( matrix(stdBySeasonRiver$lengthMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   lengthSd =   addColMeans( matrix(stdBySeasonRiver$lengthSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#
#   lengthMean0 = stdByRiver$lengthMean0
#   lengthSd0 = stdByRiver$lengthSd0
# environmental covariates pertaining to intervals.  These are
# covariates of growth and survival
# For standardizing env predictors of growth and surv
#   tempMean = addColMeans( matrix(stdBySeasonRiver$tempMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   tempSd =   addColMeans( matrix(stdBySeasonRiver$tempSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   flowMean = addColMeans( matrix(stdBySeasonRiver$flowMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   flowSd =   addColMeans( matrix(stdBySeasonRiver$flowSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
## Predictors of phi for correcting N1 where countForN ==0
#   tempForN = tempForN
#   flowForN = flowForN
# not standardizing by season,river because on NAs in river
#   tempDATA = ( as.numeric(dMData$fullMeanT) - stdBySeason$tempMean[ as.numeric(dMData$season)] ) / stdBySeason$tempSd[ as.numeric(dMData$season) ]
#   flowDATA = ( as.numeric(dMData$fullMeanD) - stdBySeason$flowMean[ as.numeric(dMData$season)] ) / stdBySeason$flowSd[ as.numeric(dMData$season) ]
# emPermNA, used to censor likelihood for permanent emigrants
# 1 on line before last observation with subsequent bottom of the study site antenna hit. 0's before and after if em, NAs otherwise
# trying emPerm without the NAs
emPermDATA = dMData$emPerm
intervalDays = as.numeric(dMData$fullMeanIntLen )
# Environmental covariates for p
flowP = as.numeric(dMData$dischargeForP)
temperatureP = as.numeric(dMData$temperatureForP)
#For standardizing env predictors of p
#   flowMeanP = addRowColMeans( matrix(stdBySeasonRiver$dischMeanP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   flowSdP = addRowColMeans( matrix(stdBySeasonRiver$dischSdP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   tempMeanP = addRowColMeans( matrix(stdBySeasonRiver$tempMeanP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
#   tempSdP = addRowColMeans( matrix(stdBySeasonRiver$tempSdP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )
# , growthSd = sd(((dMData$lagLength - dMData$length)/(as.numeric(dMData$intervalLength)))*365/4, na.rm=TRUE)
######## NEVER!!!! #########  gr = (dMData$lagLength - dMData$length)/(as.numeric(dMData$intervalLength))
# indexing of the input and state vectors
year = dMData$year-min(dMData$year) + 1
nYears = max(dMData$year)-min(dMData$year)+1
season = as.numeric(as.character(dMData$season))
nAllRows = length(dMData[,1])
nFirstObsRows = evalList$nFirstObsRows
firstObsRows = evalList$firstObsRows
nOcc = length(unique(dMData$sampleNum))
occ = dMData$sampleNum-min(dMData$sampleNum)-1
nEvalRows = evalList$nEvalRows # rows that will matter if we start using JS, and
evalRows = evalList$evalRows   # that matter now for the growth model
lastPossibleRows = subset( 1:nrow(dMData),dMData$lastAIS==dMData$ageInSamples ) # need to put this in makedMData
nLastPossibleRows = evalList$nFirstObsRows
lastObsRows = evalList$lastObsRows
nLastObsRows = evalList$nLastObsRows
lastRows = lastPossibleRows
nLastRows = nLastPossibleRows
nOut = evalList$nEvalRows # evalRows to output for each trace
#create variables that hold information on counts - data held in statsForN (made in makeDMData.R - based on pheno2Long, so has all cohorts. need to throw away years before dMData's first cohort)
minYear <- min(dMData$year)
firstYearIndex <- minYear-statsForN$minYear + 1
# countForN has dummy river 1 in it
countForN <- statsForN$countForN[,firstYearIndex:dim(statsForN$countForN)[2],]
meanForN <- statsForN$meanForN
sdForN <- statsForN$sdForN
#  dMDataF <- dMData[ dMData$first == dMData$sampleNum, ]
#  nTagged1 <- table(dMDataF$season,dMDataF$year,dMDataF$riverOrdered)
#Fill in random #s for zRiv=1
#  nTagged <- abind(matrix(round(runif(4*nYears,10,50)), nrow=4,ncol=nYears),nTagged1)
#   floodDurDATA <- floodDur
#   droughtDurDATA <- droughtDur
#   floodFreqDATA <- floodFreq
}
)
# function to make initial z matrix, with 1s when known alive and NAs otherwise
encInit<-function(sN, first, last){#, river){
z.iv <- array(NA, dim=length(first))
z.iv[(sN>=first)&(sN<=(last))] <- 1
return(z.iv)
}
emPermInit <- function(e){
eOut <- array(NA, dim=length(e))
eOut <- ifelse( is.na(e), 0, e )
return(eOut)
}
encInitMS<-function(sN, first, last, river){
for (i in 1:(length(first))){
river[i] <- river[i] - 0
if ((sN[i] >= first[i]) & (sN[i] <= (last[i]))) {
if( is.na(river[i]) ) river[i] <- river[i-1]
}
else river[i] <- NA
}
return(river + 1)
}
inits<- function(){
list(#phi = rep(0.5,length=d$nRivers),
#p = rep(0.5,length=d$nRivers),
#ppsi = matrix(rnorm(d$nRivers^2 ), d$nRivers, d$nRivers ) ,
#size = dMData$length[evalList$firstObsRows]
z = as.numeric(encInit(dMData$sampleNum, dMData$first, dMData$last))   #, #dMData$riverN)) ,
#censored = emPermInit( d$emPermDATA )
#zRiv = as.numeric(encInitMS(dMData$sampleNum,dMData$first,dMData$last,as.numeric(dMData$riverOrdered)))
)
}
# MCMC settings
nadapt <- 500
nb <- 50
ni <- 100
nt <- 5
nc <- 1
#top('Pause')
# (beforeAdapt <- Sys.time())
# print( beforeAdapt )
# model<- jags.model(
#      file = bugsName,
#     data = d,
#     inits = inits,
#     n.chains = nchains,
#     n.adapt = nadapt,
# )
# (afterAdapt <- Sys.time())
# afterAdapt - beforeAdapt
#
varsToMonitor<-c(
'pBeta'
, 'phiBeta'
, 'psiBeta'
, 'deviance'
#  , 'grSigma'
#  , 'grBeta'
)
out<-jags(data=d,
inits=inits,
parameters.to.save=varsToMonitor,
model.file='simpleCJS.txt',
n.chains=nc,
n.iter=ni,
n.burnin=nb,
n.thin=nt,
progress.bar = 'gui'
)
source('C:/Users/Evan/Desktop/Conte/simpleCJS/run.R', echo=TRUE)
warnings()
d$season
sum(is.na(d$season))
d$evalRows
error
varsToMonitor
source('C:/Users/Evan/Desktop/Conte/simpleCJS/constructModelFile.R', echo=TRUE)
source('C:/Users/Evan/Desktop/Conte/simpleCJS/run.R', echo=TRUE)
d$availableDATA
dMData$availabe01
names(dMData)
nrow(dMData)
source('C:/Users/Evan/Desktop/Conte/simpleCJS/constructModelFile.R', echo=TRUE)
source('C:/Users/Evan/Desktop/Conte/simpleCJS/run.R', echo=TRUE)
home <- file.path("~/simpleCJS")
load(file.path(dataStore,rDataName))
library(rjags)
memory.limit()
library(data.table)
install.packages(data.table)
install.packages("data.table")
library(data.table)
