{
    "contents" : "    \nlibrary(plyr)\nlibrary(rjags)\nlibrary(ggplot2)\nlibrary(abind)\nrjags::load.module(\"dic\")\n\n\ndMData$length[dMData$tagNumberCH=='1BF1FF6207' & dMData$season == 3 & dMData$year == 2005] <- NA\ndMData$length[dMData$tagNumberCH=='1BF1FF6521' & dMData$season == 3 & dMData$year == 2005] <- NA\ndMData$length[dMData$tagNumberCH=='1BF18CE7ED' & dMData$season == 2 & dMData$year == 2006] <- NA\ndMData$length[dMData$tagNumberCH=='1BF20FF1B9' & dMData$season == 3 & dMData$year == 2005] <- NA\ndMData$length[dMData$tagNumberCH=='257C67CA48' ] <- NA\ndMData$length[dMData$tagNumberCH=='1BF20EB7A4' & dMData$season == 4 & dMData$year == 2008] <- NA\n\n\n\n#dMData$riverOrdered <- factor(dMData$river,levels=c('WEST BROOK','WB JIMMY','WB MITCHELL','WB OBEAR'), ordered=T)\n\n# means for standardizing \n#####################################################################  \n# stdBySeasonRiver <- ddply( dMData, .(riverOrdered,riverN,season), summarise,   \n#  lengthMean=mean(length, na.rm=TRUE),                       \n#  lengthSd=sd(length, na.rm=TRUE),\n#  lengthLo = quantile(length,c(0.025), na.rm=TRUE),\n#  lengthHi = quantile(length,c(0.975), na.rm=TRUE),\n#  tempMean=mean(fullMeanT, na.rm=TRUE),\n#  tempMeanP=mean(temperatureForP, na.rm=TRUE), \n#  tempSd=sd(fullMeanT, na.rm=TRUE),\n#  tempSdP=sd(temperatureForP, na.rm=TRUE),\n#  tempLo = quantile(fullMeanT,c(0.025), na.rm=TRUE),\n#  tempHi = quantile(fullMeanT,c(0.975), na.rm=TRUE),\n#  flowMean=mean(fullMeanD, na.rm=TRUE), \n#  flowSd=sd(fullMeanD, na.rm=TRUE),\n#  dischMeanP=mean(dischargeForP,na.rm=T),\n#  dischSdP=sd(dischargeForP,na.rm=T),\n#  flowLo = quantile(fullMeanD,c(0.025), na.rm=TRUE),\n#  flowHi = quantile(fullMeanD,c(0.975), na.rm=TRUE) )\n# ############# To get rid of NA Rivers\n# stdBySeasonRiver<-stdBySeasonRiver[!is.na(stdBySeasonRiver$riverN),]\n# \n# #####################################################################  \n# stdBySeason <- ddply( dMData, .(season), summarise,   \n#  lengthMean=mean(length, na.rm=TRUE), \n#  lengthSd=sd(length, na.rm=TRUE),\n#  lengthLo = quantile(length,c(0.025), na.rm=TRUE),\n#  lengthHi = quantile(length,c(0.975), na.rm=TRUE),\n#  tempMean=mean(fullMeanT, na.rm=TRUE),\n#  tempMeanP=mean(temperatureForP, na.rm=TRUE), \n#  tempSd=sd(fullMeanT, na.rm=TRUE),\n#  tempSdP=sd(temperatureForP, na.rm=TRUE),\n#  tempLo = quantile(fullMeanT,c(0.025), na.rm=TRUE),\n#  tempHi = quantile(fullMeanT,c(0.975), na.rm=TRUE),\n#  flowMean=mean(fullMeanD, na.rm=TRUE), \n#  flowSd=sd(fullMeanD, na.rm=TRUE),\n#  dischMeanP=mean(dischargeForP,na.rm=T),\n#  dischSdP=sd(dischargeForP,na.rm=T),\n#  flowLo = quantile(fullMeanD,c(0.025), na.rm=TRUE),\n#  flowHi = quantile(fullMeanD,c(0.975), na.rm=TRUE) ) \n# \n# # standardize by river  - for age0 fall lengths\n# stdByRiver <- ddply( dMData, .(riverOrdered,riverN), summarise,\n# lengthSd0 = sd(subset( length, age == 0 & season == 3 ), na.rm=TRUE),\n# lengthMean0 = mean(subset( length, age == 0 & season == 3 ), na.rm=TRUE) )\n# \n# stdByRiver <- stdByRiver[!is.na(stdByRiver$riverN),]\n# stdByRiver$river <- as.numeric(stdByRiver$riverOrdered)\n\n#stdBySeasonRiver<-rbind(stdBySeasonRiver,c('zRiv1','0',rep(NA,ncol(stdBySeasonRiver)-2)))     \n\n#####\n# # fdDATA is flood and drought frequencies and durations\n# fdDATA$year <- as.numeric( fdDATA$year )\n# fdDATA$year2 <- fdDATA$year\n# fdDATA$year <- fdDATA$year-min(fdDATA$year) + 1\n# \n# floodDur <- matrix(0,max(fdDATA$season),max(fdDATA$year))\n# droughtDur <- matrix(0,max(fdDATA$season),max(fdDATA$year))\n# floodFreq <- matrix(0,max(fdDATA$season),max(fdDATA$year))\n# for ( i in 1:nrow(fdDATA) ){\n#   floodDur[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$floodDur[i]\n#   droughtDur[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$droughtDur[i]\n#   floodFreq[fdDATA$season[i],fdDATA$year[i]] <- fdDATA$floodFreq[i]\n#   \n# }\n#####\n\n\n# function to add dummy rows and columns for zRiv=1\naddRowColMeans <- function(m){\n  m <- cbind( rowMeans(m),m )\n  m <- rbind( colMeans(m),m )\n  return ( m )  \n}\n# function to add dummy columns for zRiv=1\naddColMeans <- function(m){\n  m <- cbind( rowMeans(m),m )\n  return ( m )  \n}\n\n\n\n# tempForN<- array(NA,dim=c(4,5,max(dMData$year-min(dMData$year) + 1)))\n# for(s in 1:4){            \n#   for(y in 1:max(dMData$year-min(dMData$year) + 1)){\n#       tempForN[s,1,y]<-(stdBySeason$tempMean[s]- stdBySeason$tempMean[s] ) / stdBySeason$tempSd[ s ]\n#     for(r in 1:4){\n#       tempForN[s,r+1,y]<-(mean(dMData$fullMeanT[dMData$season==s&as.numeric(dMData$riverOrdered)==r&(dMData$year-min(dMData$year) + 1)==y],na.rm=T)\n#                           - stdBySeason$tempMean[ s] ) / stdBySeason$tempSd[ s ]\n#       if(tempForN[s,r+1,y]=='NaN')tempForN[s,r+1,y]<-(stdBySeason$tempMean[s]- stdBySeason$tempMean[ s] ) / stdBySeason$tempSd[ s ]\n#     }\n#   }\n# }\n\n# flowForN<- array(NA,dim=c(4,5,max(dMData$year-min(dMData$year) + 1)))\n# for(s in 1:4){            \n#   for(y in 1:max(dMData$year-min(dMData$year) + 1)){\n#       flowForN[s,1,y]<-(stdBySeason$flowMean[s]- stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]\n#     for(r in 1:4){\n#       flowForN[s,r+1,y]<-(mean(dMData$fullMeanD[dMData$season==s&as.numeric(dMData$riverOrdered)==r&(dMData$year-min(dMData$year) + 1)==y],na.rm=T)\n#                           - stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]\n#       if(flowForN[s,r+1,y]=='NaN')flowForN[s,r+1,y]<-(stdBySeason$flowMean[s]- stdBySeason$flowMean[s] ) / stdBySeason$flowSd[s]\n#     }\n#   }\n# }\n\n\nknownZ<-function(sN, first, last){#, river){\n  z.iv <- array(NA, dim=length(first))\n  z.iv[(sN>first)&(sN<=(last))] <- 1\n  return(z.iv)\n}\n\n\n############ Predictors that are in a matrix have season in rows and river in columns\nd <- within(\n       data = list(),\n       expr = {\n  \n  encDATA = as.numeric(dMData$enc) #$msEnc\n  riverDATA = dMData$riverN #-3\n  nRivers = length(unique(dMData$riverN))-1 #may need to add one for unobs\n  #lengthDATA = dMData$length\n  #availableDATA = dMData$available01\n  #ind = as.numeric(factor(dMData$tag))\n # For standardizing length\n#   lengthMean = addColMeans( matrix(stdBySeasonRiver$lengthMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   lengthSd =   addColMeans( matrix(stdBySeasonRiver$lengthSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )  \n#   \n#   lengthMean0 = stdByRiver$lengthMean0\n#   lengthSd0 = stdByRiver$lengthSd0\n # environmental covariates pertaining to intervals.  These are\n # covariates of growth and survival\n\n  # For standardizing env predictors of growth and surv\n#   tempMean = addColMeans( matrix(stdBySeasonRiver$tempMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   tempSd =   addColMeans( matrix(stdBySeasonRiver$tempSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )  \n#   flowMean = addColMeans( matrix(stdBySeasonRiver$flowMean,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   flowSd =   addColMeans( matrix(stdBySeasonRiver$flowSd,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )  \n\n ## Predictors of phi for correcting N1 where countForN ==0\n#   tempForN = tempForN\n#   flowForN = flowForN\n\n  # not standardizing by season,river because on NAs in river\n#   tempDATA = ( as.numeric(dMData$fullMeanT) - stdBySeason$tempMean[ as.numeric(dMData$season)] ) / stdBySeason$tempSd[ as.numeric(dMData$season) ]\n#   flowDATA = ( as.numeric(dMData$fullMeanD) - stdBySeason$flowMean[ as.numeric(dMData$season)] ) / stdBySeason$flowSd[ as.numeric(dMData$season) ]  \n\n  # emPermNA, used to censor likelihood for permanent emigrants\n  # 1 on line before last observation with subsequent bottom of the study site antenna hit. 0's before and after if em, NAs otherwise\n  # trying emPerm without the NAs \n  #emPermDATA = dMData$emPerm \n\n  #intervalDays = as.numeric(dMData$fullMeanIntLen )\n # Environmental covariates for p \n  #flowP = as.numeric(dMData$dischargeForP)\n  #temperatureP = as.numeric(dMData$temperatureForP)\n #For standardizing env predictors of p\n#   flowMeanP = addRowColMeans( matrix(stdBySeasonRiver$dischMeanP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   flowSdP = addRowColMeans( matrix(stdBySeasonRiver$dischSdP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   tempMeanP = addRowColMeans( matrix(stdBySeasonRiver$tempMeanP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n#   tempSdP = addRowColMeans( matrix(stdBySeasonRiver$tempSdP,nrow=length(unique(dMData$season)),ncol=length(unique(as.numeric(dMData$riverN)-0))-1) )\n\n# , growthSd = sd(((dMData$lagLength - dMData$length)/(as.numeric(dMData$intervalLength)))*365/4, na.rm=TRUE)\n######## NEVER!!!! #########  gr = (dMData$lagLength - dMData$length)/(as.numeric(dMData$intervalLength))\n# indexing of the input and state vectors\n  year = dMData$year-min(dMData$year) + 1\n  nYears = max(dMData$year)-min(dMData$year)+1\n  season = as.numeric(as.character(dMData$season)) \n  nAllRows = nrow(dMData)\n  nFirstObsRows = evalList$nFirstObsRows\n  firstObsRows = evalList$firstObsRows\n  #nOcc = length(unique(dMData$sampleNum))\n  #occ = dMData$sampleNum-min(dMData$sampleNum)-1\n  nEvalRows = evalList$nEvalRows # rows that will matter if we start using JS, and \n  evalRows = evalList$evalRows   # that matter now for the growth model\n  z = dMData[,knownZ(sampleNum,first,last)]\n  #lastPossibleRows = subset( 1:nrow(dMData),dMData$lastAIS==dMData$ageInSamples ) # need to put this in makedMData\n  #nLastPossibleRows = evalList$nFirstObsRows\n\n  #lastObsRows = evalList$lastObsRows\n  #nLastObsRows = evalList$nLastObsRows\n\n  #lastRows = lastPossibleRows\n  #nLastRows = nLastPossibleRows\n\n  #nOut = evalList$nEvalRows # evalRows to output for each trace\n  \n  #create variables that hold information on counts - data held in statsForN (made in makeDMData.R - based on pheno2Long, so has all cohorts. need to throw away years before dMData's first cohort)\n  #minYear <- min(dMData$year)\n  #firstYearIndex <- minYear-statsForN$minYear + 1\n  # countForN has dummy river 1 in it\n  #countForN <- statsForN$countForN[,firstYearIndex:dim(statsForN$countForN)[2],]\n\n  #meanForN <- statsForN$meanForN\n  #sdForN <- statsForN$sdForN\n\n#  dMDataF <- dMData[ dMData$first == dMData$sampleNum, ]\n#  nTagged1 <- table(dMDataF$season,dMDataF$year,dMDataF$riverOrdered)\n\n  #Fill in random #s for zRiv=1\n#  nTagged <- abind(matrix(round(runif(4*nYears,10,50)), nrow=4,ncol=nYears),nTagged1)\n#   floodDurDATA <- floodDur\n#   droughtDurDATA <- droughtDur\n#   floodFreqDATA <- floodFreq\n\n }\n)\n\n\n# function to make initial z matrix, with 1s when known alive and NAs otherwise\n\nzInit<-d$z\nzInit[is.na(zInit)]<-0\nzInit[d$firstObsRows]<-NA\nzInit[zInit==1]<-NA\n\nemPermInit <- function(e){\n  eOut <- array(NA, dim=length(e))\n  eOut <- ifelse( is.na(e), 0, e )\n  return(eOut)\n}\n\nencInitMS<-function(sN, first, last, river){\n   for (i in 1:(length(first))){\n     river[i] <- river[i] - 0\n     if ((sN[i] >= first[i]) & (sN[i] <= (last[i]))) {\n       if( is.na(river[i]) ) river[i] <- river[i-1]  \n     }\n     else river[i] <- NA\n   }  \n   return(river + 1)\n}\n\ninits<- function(){\n  list(phiBeta = array(0.5,dim=c(4,d$nYears,d$nRivers+1)),\n       pBeta = array(0.5,dim=c(4,d$nYears,d$nRivers+1))\n       #psiBeta = array(0, dim=c(4,d$nRivers,d$nRivers)),\n       #size = dMData$length[evalList$firstObsRows]\n       #z = zInit,\n       #censored = emPermInit( d$emPermDATA )\n       #zRiv = as.numeric(encInitMS(dMData$sampleNum,dMData$first,\n      #                    dMData$last,dMData$riverN))\n       )      \n  }\n\n\n   \n# MCMC settings\nna <- 500\nnb <- 2000\nni <- 5000\nnt <- 5\nnc <- 3\n\nvarsToMonitor<-c(\n\n  \n    'pBeta'\n\n  , 'phiBeta'\n\n  , 'psiBeta'\n\n  , 'deviance'\n   \n#  , 'grSigma' \n#  , 'grBeta'\n\n)\n\n# out <- bugs(\n#   data=d,\n#   inits=inits,\n#   model = \"simpleCJS.txt\",\n#   parameters.to.save = varsToMonitor,\n#   n.chains=nc,\n#   n.iter = ni,\n#   n.thin = nt,\n#   n.burnin=nb,\n#   debug=T)\n\nrm(dMData)\nrm(evalList)\ngc()\n\n(beforeAdapt <- Sys.time())\nprint( beforeAdapt )\nadaptedModel<- jags.model(\n  file = bugsName,  \n  data = d,\n  inits = inits,\n  n.chains = nc,\n  n.adapt = na,             \n)\n(afterAdapt <- Sys.time())\nafterAdapt - beforeAdapt\n\n# out1=out  ## for running a second set of iters\n\n( beforeJags <- Sys.time() )\nprint( beforeJags )\nout <- jags.samples(\n  model = adaptedModel,\n  variable.names = varsToMonitor,\n  n.iter = ni,\n  thin = nt,\n  progress.bar = 'text'\n) \n\n( done <- Sys.time() )\n\nprint(afterAdapt - beforeAdapt) \nprint(done - beforeJags)",
    "created" : 1428670532307.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3237833873",
    "id" : "321D18B7",
    "lastKnownWriteTime" : 1428751475,
    "path" : "~/simpleCJS/callSimpleCJS.R",
    "project_path" : "callSimpleCJS.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}